{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from collections import Counter, defaultdict"
      ],
      "metadata": {
        "id": "iD0Y0SNWXLt0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    nltk.data.find(\"tokenizers/punkt\")\n",
        "except LookupError:\n",
        "    nltk.download(\"punkt\")\n",
        "try:\n",
        "    nltk.data.find(\"corpora/stopwords\")\n",
        "except LookupError:\n",
        "    nltk.download(\"stopwords\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzTbGJosYE96",
        "outputId": "a001a190-0291-47b5-8f0e-3539ac33a3ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_frequency(text: str, sentences: int = 3) -> str:\n",
        "    sents = sent_tokenize(text)\n",
        "    if len(sents) <= sentences:\n",
        "        return text.strip()\n",
        "\n",
        "    words = word_tokenize(re.sub(r\"\\s+\", \" \", text.lower()))\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    words = [w for w in words if re.match(r\"[a-zA-Z0-9]\", w) and w not in stops]\n",
        "\n",
        "    freq = Counter(words)\n",
        "\n",
        "    scores = defaultdict(float)\n",
        "    for i, s in enumerate(sents):\n",
        "        for w in word_tokenize(s.lower()):\n",
        "            if w in freq:\n",
        "                scores[i] += freq[w]\n",
        "\n",
        "    top_idx = sorted(sorted(scores, key=scores.get, reverse=True)[:sentences])\n",
        "    return \" \".join(sents[i].strip() for i in top_idx)"
      ],
      "metadata": {
        "id": "oCETEBX6YJ7U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"\n",
        "Artificial Intelligence (AI) is transforming the world by automating tasks,\n",
        "analyzing massive amounts of data, and enabling new forms of creativity.\n",
        "From healthcare and education to finance and transportation, AI is making\n",
        "processes faster, more accurate, and more efficient. However, it also raises\n",
        "ethical concerns about job loss, privacy, and decision transparency.\n",
        "Understanding how to balance innovation with responsibility is key to\n",
        "building a better AI-powered future.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "U7YblSquYqyY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "711e4426",
        "outputId": "fa3a374a-303f-40b0-8aae-1f3e2dbf721f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(summarize_frequency(text, sentences=3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVeYo2zfY9bX",
        "outputId": "7060c297-1247-4df6-c3b8-ff7b0cd28ae4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Artificial Intelligence (AI) is transforming the world by automating tasks,\n",
            "analyzing massive amounts of data, and enabling new forms of creativity. From healthcare and education to finance and transportation, AI is making\n",
            "processes faster, more accurate, and more efficient. However, it also raises\n",
            "ethical concerns about job loss, privacy, and decision transparency.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elt8xLPKZoUM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}